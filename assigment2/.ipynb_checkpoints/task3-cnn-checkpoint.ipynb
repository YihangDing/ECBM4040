{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECBM E4040 - Assignment 2 - Task 3: Convolutional Neural Network (CNN)\n",
    "\n",
    "In this task, you are going to first practice the forward/backward propagation of the convolutional operations with Numpy. After that, we will introduce TensorFlow with which you'll create your CNN model for an image classification task. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNNs:\n",
    "This is one of the good posts describing CNNs:\n",
    "\n",
    "[https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/](https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/)\n",
    "\n",
    "Convolutional neural networks (CNNs) are a type of neural networks which is highly effective for image processing. \n",
    "\n",
    "Remember when we build an MLP model, each input is multiplied by its own weights. When the input dimension or the first layer is too large, we will need a giant matrix to store our weights. This could easily become a problem in image processing since the dimension of a vectorized image could easily exceed 1000 (consider CIFAR-10 which has images of shape 32Ã—32=1024, yet the resolution is so low). \n",
    "\n",
    "In CNN, the weights can be shared: the same filter (also known as 'weights' or 'kernel') moves over the input, and at each position an output value is calculated. This means the same weights are used by the entire input, therefore saving a lot of memory.\n",
    "\n",
    "![Illustration of the CNN](./ecbm4040/notebook_images/task3_1.jpg)\n",
    "Image source: [here](https://developer.apple.com/library/content/documentation/Performance/Conceptual/vImage/ConvolutionOperations/ConvolutionOperations.html)\n",
    "\n",
    "__Convolution:__  In the picture above, the input is a 7-by-7 image, and the filter is shown as a blue 3-by-3 grid. The filter overlaps with the top-left corner of the input, and we perform an element-wise multiplication followed by a summation, then put the sum into the output matrix. The filter then moves several pixels right, covering a new input area so a new sum can be derived.\n",
    "\n",
    "__Training:__ One thing to remember is that there would be a lot of filters for each layer in a CNN, and the goal of training is to find the best filters for your task. Each filter tries to capture one specific feature. Typically, in the first convolutional layer which directly looks at your input, the filters try to capture information about color and edges which we know as local features; in higher layers, due to the effect of max-pooling, the receptive-fields of filters becomes large so more global and complex features can be detected. \n",
    "\n",
    "__Architecture:__ For classification tasks, a CNN usually starts with convolution followed by max-pooling. After that, the feature maps will be flattened so that we could append fully connected layers. Common activation functions include ReLu, ELU in the convolution layers, and softmax in the fully connected layers (to calculate the classification scores).\n",
    "\n",
    "---\n",
    "\n",
    "### Terminology\n",
    "\n",
    "* __Convolution__: element-wise multiplication followed by summation of your input and one of your filters in the CNN context.\n",
    "* __Filter/kernel/weights__: a grid or a set of grids typically smaller than your input size that moves over the input space to generate output. Each filter captures one type of feature.\n",
    "* __Feature/feature maps__: the output of a hidden layer. Think of it as another representation of your data. \n",
    "* __Pooling__: an downsampling operation that joins local information together, so the higher layers' receptive fields can be bigger. The most seen pooling operation is max-pooling, which outputs the maximum of all values inside the pool.\n",
    "* __Flatten__: a junction between convolution layers and fully connected layers. Used to turn 2-D feature maps into 1-D. For tasks such as image segmentation where the output also needs to be 2-D, this won't be used.\n",
    "* __Border mode__: usually refers to 'VALID' or 'SAME'. Under 'VALID' mode, only when the filter and the input fully overlap can a convolution be conducted; under 'SAME' mode, the output size is the same as the input size (only when the stride is 1), and when the filter and the input don't fully overlap (happens at the edge/corner of input) we pad zeroes (or other designated numbers) and then do convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import modules\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from ecbm4040.cifar_utils import load_data\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Getting a sense of convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conv2d feedforward\n",
    "\n",
    "Implement a Numpy naive 2-D convolution feedforward function. We ask you to simply do the element-wise multiplication and summation. Also, don't need to worry about the efficiency of your function. Use loops as many as you like.\n",
    "\n",
    "<span style=\"color:red\">__TODO:__</span> Finish the function __conv2d_forward__ in __ecbm4040/layer_funcs.py__. After that, run the following cell blocks, which will give the output of your convolution function. Detailed instructions have been given in the comments of __layer_func.py__. __We need to judge your output to give you credits__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[-0.04138903  0.11338093  0.2681509 ]\n",
      "   [-0.09391829  0.14671108  0.38734045]]\n",
      "\n",
      "  [[-0.31590063  0.18230696  0.68051454]\n",
      "   [-0.41135959  0.1727074   0.75677438]]]\n",
      "\n",
      "\n",
      " [[[-0.79122782  0.7372926   2.26581303]\n",
      "   [-0.92961649  0.68476334  2.29914317]]\n",
      "\n",
      "  [[-1.40917703  0.46278101  2.33473905]\n",
      "   [-1.5904954   0.36732205  2.32513949]]]]\n"
     ]
    }
   ],
   "source": [
    "from ecbm4040.layer_funcs import conv2d_forward\n",
    "\n",
    "# Set test parameters.\n",
    "x_shape = (2, 4, 4, 3)\n",
    "w_shape = (3, 4, 4, 3)\n",
    "x = np.linspace(-0.1, 0.5, num=np.prod(x_shape)).reshape(x_shape)\n",
    "w = np.linspace(-0.2, 0.3, num=np.prod(w_shape)).reshape(w_shape)\n",
    "b = np.linspace(-0.1, 0.2, num=3)\n",
    "pad = 1\n",
    "stride = 2\n",
    "your_feedforward = conv2d_forward(x, w, b, pad, stride)\n",
    "print(your_feedforward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conv2d backpropogation (optional, bonus +10 points)\n",
    "\n",
    "<p style=\"color:red\">This function is optional, but a bonus 10 points will be given if you solve it correctly.</p>\n",
    "\n",
    "Implement a Numpy naive 2-D convolution backpropagation function. Again, don't worry about the efficienty.\n",
    "\n",
    "<span style=\"color:red\">__TODO:__</span> Finish the function __conv2d_backward__ in __ecbm4040/layer_funcs.py__. After that, run the following cell blocks, which will give the output of your backpropagation. Detailed instructions have been given in the comments of __layer_func.py__. __We need to judge your output to give you credits__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ecbm4040.layer_funcs import conv2d_backward\n",
    "# Set test parameters. Please don't change it.\n",
    "np.random.seed(123)\n",
    "d_top = np.random.normal(size=your_feedforward.shape)\n",
    "your_dw, your_db = conv2d_backward(d_top, x, w, b, pad, stride)\n",
    "print(your_dw)\n",
    "print('*'*50)\n",
    "print(your_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### max pool feedforward\n",
    "\n",
    "Implement a Numpy naive max pool feedforward function. We ask you to simply find the max in your pooling window. Also, don't need to worry about the efficiency of your function. Use loops as many as you like.\n",
    "\n",
    "<span style=\"color:red\">__TODO:__</span> Finish the function __max_pool_forward__ in __ecbm4040/layer_funcs.py__. After that, run the following cell blocks, which will give the output of your max pool function. Detailed instructions have been given in the comments of __layer_func.py__. __We need to judge your output to give you credits__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[-0.34210526 -0.33157895 -0.32105263]\n",
      "   [-0.27894737 -0.26842105 -0.25789474]]\n",
      "\n",
      "  [[-0.08947368 -0.07894737 -0.06842105]\n",
      "   [-0.02631579 -0.01578947 -0.00526316]]]\n",
      "\n",
      "\n",
      " [[[ 0.16315789  0.17368421  0.18421053]\n",
      "   [ 0.22631579  0.23684211  0.24736842]]\n",
      "\n",
      "  [[ 0.41578947  0.42631579  0.43684211]\n",
      "   [ 0.47894737  0.48947368  0.5       ]]]]\n"
     ]
    }
   ],
   "source": [
    "from ecbm4040.layer_funcs import max_pool_forward\n",
    "\n",
    "# Set test parameters.\n",
    "x_shape = (2, 4, 4, 3)\n",
    "x = np.linspace(-0.5, 0.5, num=np.prod(x_shape)).reshape(x_shape)\n",
    "pool_size = 2\n",
    "stride = 2\n",
    "\n",
    "your_feedforward = max_pool_forward(x, pool_size, stride)\n",
    "print(your_feedforward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### max pool backpropogation (optional, bonus +10 points)\n",
    "\n",
    "<p style=\"color:red\">This function is optional, but a bonus 10 points will be given if you solve it correctly.</p>\n",
    "\n",
    "Implement a Numpy naive max pooling backpropagation function. Again, don't worry about the efficiency.\n",
    "\n",
    "<span style=\"color:red\">__TODO:__</span> Finish the function __max_pool_backward__ in __ecbm4040/layer_funcs.py__. After that, run the following cell blocks, which will give the output of your backpropagation. Detailed instructions have been given in the comments of __layer_func.py__. __We need to judge your output to give you credits__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ecbm4040.layer_funcs import max_pool_backward\n",
    "\n",
    "# Set test parameters. Please don't change it.\n",
    "np.random.seed(123)\n",
    "dout = np.random.normal(size=your_feedforward.shape)\n",
    "your_dx = max_pool_backward(dout, x, pool_size, stride)\n",
    "print(your_dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: TensorFlow CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we will construct the CNN in TensorFlow. To be more specific, we are going to implement a CNN similar to the LeNet structure.\n",
    "\n",
    "Tensorflow offers many useful resources and functions which help developers build the net in a high-level fashion, such as functions in the `layer` module. However, we will build the network by ourself for this homework for better understanding. By utilizing functions in `tf.nn` that exist for Neural Network structuring and training, we can build out our own layers and network modules rather quickly.\n",
    "\n",
    "Also, we will introduce a visualization tool called Tensorboard. You can use TensorBoard to visualize your TensorFlow graph, plot quantitative metrics about the execution of your graph, and show additional data that pass through it.\n",
    "\n",
    "Resources and References: <br>\n",
    "* [TensorBoard: Visualizing Learning](https://www.tensorflow.org/get_started/summaries_and_tensorboard)<br>\n",
    "* [Convolutional Neural Networks (LeNet) - DeepLearning 0.1 documentation](http://deeplearning.net/tutorial/lenet.html)<br>\n",
    "* [LeNet-5, convolutional neural networks](http://yann.lecun.com/exdb/lenet/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick guide for Tensorboard\n",
    "\n",
    "Tensorboard is a powerful tool provided by TensorFlow. It allows developers to check their graph and trend of parameters. This guide will give you a basic under standing on how to set up Tensorboard graph in your code, start tensorboard on your local machine/GCP instance and how to access the interface.\n",
    "\n",
    "For complete instructions, check the official guide on Tensorflow web site [here](https://www.tensorflow.org/get_started/summaries_and_tensorboard).\n",
    "\n",
    "### How to start tensorboard\n",
    "\n",
    "#### Local\n",
    "\n",
    "To start your Tensorboard on your local machine, you need to specify a log directory for the service to fetch the graph. For example, in your command line, type:\n",
    "\n",
    "```shell\n",
    "$ tensorboard --logdir=\"~/log\"\n",
    "```\n",
    "\n",
    "Then, Tensorboard will start running. By default, it will be running on port 6006:\n",
    "\n",
    "``` shell\n",
    "TensorBoard 1.8.0 at http://localhost:6006 (Press CTRL+C to quit)\n",
    "```\n",
    "\n",
    "Make sure Tensorboard is running, you can visit http://localhost:6006 In your browser and you should be able to see the main page of Tensorboard. If the page is shown as below, it means Tensorboard is running correctly. The report is due to lack of event file, but we can just leave it there for now.\n",
    "\n",
    "![Tensorboard_1](./ecbm4040/notebook_images/task3_2_1.png)\n",
    "\n",
    "#### GCP\n",
    "\n",
    "To set up the Tensorboard on GCP is the same as above. However, we're not able to check the Tensorboard UI directly through our browser. In order to visit the page through our local browser, we should link the port of our local machine to the port on GCP. It is similar to what we did previously for Jupyter Notebook.\n",
    "\n",
    "In the command line on your local machine, type:\n",
    "\n",
    "```shell\n",
    "$ gcloud compute ssh --ssh-flag=\"-L 9999:localhost:9999 -L 9998:localhost:6006\" \"ecbm4040@YOUR_INSTANCE\"\n",
    "```\n",
    "\n",
    " This will bind your port of your local machine to the port on GCP instance. In this case, your local port 9999 is binded with 9999 on GCP, while local port 9998 is binded with 6006 on GCP. You can change whatever port you like as long as it does not confilct with your local services.\n",
    "\n",
    "After connecting to GCP using the command, you will be able to see the result page.\n",
    "\n",
    "\n",
    "\n",
    "### Export Tensorboard events into log directory\n",
    "\n",
    "To generate data files for Tensorboard, we should use class `tf.summary.FileWriter`. This class will save your network graph sturcuture and all the variable summary. \n",
    "\n",
    "For example, in `cnn_sample.py `, the file writer will save the graph and the summary into a directory based on the current timestamp. Here is the code snippet:\n",
    "\n",
    "```python\n",
    "cur_model_name = 'lenet_{}'.format(int(time.time()))\n",
    "# ...\n",
    "\n",
    "# set up summary writer for tensorboard\n",
    "merge = tf.summary.merge_all()\t# merge all the summary for variables for execution\n",
    "writer = tf.summary.FileWriter(\"log/{}\".format(cur_model_name), sess.graph)\n",
    "```\n",
    "\n",
    "The following code will save all the parameter summary and marked with iteration_total. These data will be displayed in the Tensorboard latter on.\n",
    "\n",
    "```python\n",
    "# ... previous code ...\n",
    "# ...\n",
    "\t\t\t\tif iter_total % 100 == 0:\n",
    "                    # do validation\n",
    "                    valid_eve, merge_result = sess.run([eve, merge], feed_dict={xs: X_val, ys: y_val})\n",
    "                    valid_acc = 100 - valid_eve * 100 / y_val.shape[0]\n",
    "                    if verbose:\n",
    "                        print('{}/{} loss: {} validation accuracy : {}%'.format(\n",
    "                            batch_size * (itr + 1),\n",
    "                            X_train.shape[0],\n",
    "                            cur_loss,\n",
    "                            valid_acc))\n",
    "\n",
    "                    # save the merge result summary\n",
    "                    writer.add_summary(merge_result, iter_total)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### Check the graph and summary in Tensorboard\n",
    "\n",
    "After executing the program once, you should able to see the graph displayed in the tensorboard. You can zoom in or zoom out or click into the layer block to check all the variables and tensor operations.\n",
    "\n",
    "![Tensorboard_2](./ecbm4040/notebook_images/task3_2_2.png)\n",
    "\n",
    "Also, you may able to check the trend of the variables and the distribution of those in Scalar, Distributions and Histograms. You may explore the tensorboard by yourself and take advantage to it for debuging the nerwork structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">__TODO:__</span> You will try to achieve your own CNN model that has similar structure to LeNet, show the model graph in tensorboard, and get a model with **65%** or higher accuracy using the data we provide you.\n",
    "\n",
    "An example code is included in __ecbm4040/neuralnets/cnn_sample.py__. This sample is used as a guide line for how to build a Neural Net model in Tensorflow. Feel free to utilize or change the code we give you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "<p style=\"color:red\">The following cell loads the data for you. You don't need to change them.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/cifar-10-python.tar.gz already exists. Begin extracting...\n",
      "Train data shape:  (49000, 32, 32, 3)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 32, 32, 3)\n",
      "Validation labels shape:  (1000,)\n"
     ]
    }
   ],
   "source": [
    "# Load the raw CIFAR-10 data.\n",
    "X_train, y_train = load_data(mode='train')\n",
    "\n",
    "# Data organizations:\n",
    "# Train data: 49000 samples from original train set: 1~49000\n",
    "# Validation data: 1000 samples from original train set: 49000~50000\n",
    "num_training = 49000\n",
    "num_validation = 1000\n",
    "\n",
    "X_val = X_train[-num_validation:, :]\n",
    "y_val = y_train[-num_validation:]\n",
    "\n",
    "X_train = X_train[:num_training, :]\n",
    "y_train = y_train[:num_training]\n",
    "\n",
    "# Preprocessing: subtract the mean value across every dimension for training data, and reshape it to be RGB size\n",
    "mean_image = np.mean(X_train, axis=0)\n",
    "X_train = X_train.astype(np.float32) - mean_image.astype(np.float32)\n",
    "X_val = X_val.astype(np.float32) - mean_image\n",
    "\n",
    "X_train = X_train.reshape([-1,32,32,3]) / 255\n",
    "X_val = X_val.reshape([-1,32,32,3]) / 255\n",
    "\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN model example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building my LeNet. Parameters: \n",
      "conv_featmap=[6]\n",
      "fc_units=[84]\n",
      "conv_kernel_size=[5]\n",
      "pooling_size=[2]\n",
      "l2_norm=0.01\n",
      "seed=235\n",
      "learning_rate=0.01\n",
      "WARNING:tensorflow:From /Users/apple/Documents/ColumbiaU/ecbm4040/assignment2/ecbm4040/neuralnets/cnn_sample.py:202: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "number of batches for training: 200\n",
      "epoch 1 \n",
      "Best validation accuracy! iteration:100 accuracy: 16.5%\n",
      "Best validation accuracy! iteration:200 accuracy: 18.400000000000006%\n",
      "epoch 2 \n",
      "Best validation accuracy! iteration:300 accuracy: 18.5%\n",
      "Best validation accuracy! iteration:400 accuracy: 20.0%\n",
      "epoch 3 \n",
      "Best validation accuracy! iteration:500 accuracy: 21.599999999999994%\n",
      "Best validation accuracy! iteration:600 accuracy: 21.799999999999997%\n",
      "epoch 4 \n",
      "Best validation accuracy! iteration:700 accuracy: 22.5%\n",
      "Best validation accuracy! iteration:800 accuracy: 23.700000000000003%\n",
      "epoch 5 \n",
      "Best validation accuracy! iteration:900 accuracy: 24.200000000000003%\n",
      "Best validation accuracy! iteration:1000 accuracy: 25.299999999999997%\n",
      "epoch 6 \n",
      "Best validation accuracy! iteration:1100 accuracy: 25.599999999999994%\n",
      "Best validation accuracy! iteration:1200 accuracy: 26.200000000000003%\n",
      "epoch 7 \n",
      "Best validation accuracy! iteration:1300 accuracy: 26.799999999999997%\n",
      "Best validation accuracy! iteration:1400 accuracy: 27.5%\n",
      "epoch 8 \n",
      "Best validation accuracy! iteration:1500 accuracy: 28.200000000000003%\n",
      "Best validation accuracy! iteration:1600 accuracy: 28.299999999999997%\n",
      "epoch 9 \n",
      "Best validation accuracy! iteration:1700 accuracy: 28.900000000000006%\n",
      "Best validation accuracy! iteration:1800 accuracy: 29.099999999999994%\n",
      "epoch 10 \n",
      "Best validation accuracy! iteration:1900 accuracy: 30.200000000000003%\n",
      "epoch 11 \n",
      "Best validation accuracy! iteration:2100 accuracy: 30.400000000000006%\n",
      "epoch 12 \n",
      "Best validation accuracy! iteration:2400 accuracy: 30.799999999999997%\n",
      "epoch 13 \n",
      "Best validation accuracy! iteration:2500 accuracy: 31.0%\n",
      "epoch 14 \n",
      "epoch 15 \n",
      "Best validation accuracy! iteration:2900 accuracy: 31.200000000000003%\n",
      "epoch 16 \n",
      "Best validation accuracy! iteration:3100 accuracy: 32.099999999999994%\n",
      "epoch 17 \n",
      "Best validation accuracy! iteration:3300 accuracy: 32.3%\n",
      "epoch 18 \n",
      "Best validation accuracy! iteration:3500 accuracy: 32.900000000000006%\n",
      "epoch 19 \n",
      "Best validation accuracy! iteration:3700 accuracy: 33.3%\n",
      "epoch 20 \n",
      "Best validation accuracy! iteration:3900 accuracy: 33.599999999999994%\n",
      "Traning ends. The best valid accuracy is 33.599999999999994. Model named lenet_1540864769.\n"
     ]
    }
   ],
   "source": [
    "from ecbm4040.neuralnets.cnn_sample import training\n",
    "tf.reset_default_graph()\n",
    "training(X_train, y_train, X_val, y_val, \n",
    "         conv_featmap=[6],\n",
    "         fc_units=[84],\n",
    "         conv_kernel_size=[5],\n",
    "         pooling_size=[2],\n",
    "         l2_norm=0.01,\n",
    "         seed=235,\n",
    "         learning_rate=1e-2,\n",
    "         epoch=20,\n",
    "         batch_size=245,\n",
    "         verbose=False,\n",
    "         pre_trained_model=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the model structure graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1000px;height:620px;border:0\" srcdoc=\"\n",
       "        <script src=&quot;//cdnjs.cloudflare.com/ajax/libs/polymer/0.3.3/platform.js&quot;></script>\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.8894366973273261&quot;).pbtxt = 'node {\\n  name: &quot;inputs/Placeholder&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 32\\n        }\\n        dim {\\n          size: 32\\n        }\\n        dim {\\n          size: 3\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;inputs/Placeholder_1&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;inputs/is_training&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;conv_layer_0/conv_kernel_0/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@conv_layer_0/conv_kernel_0&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\005\\\\000\\\\000\\\\000\\\\005\\\\000\\\\000\\\\000\\\\003\\\\000\\\\000\\\\000\\\\006\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;conv_layer_0/conv_kernel_0/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@conv_layer_0/conv_kernel_0&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.1632993221282959\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;conv_layer_0/conv_kernel_0/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@conv_layer_0/conv_kernel_0&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.1632993221282959\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;conv_layer_0/conv_kernel_0/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;conv_layer_0/conv_kernel_0/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@conv_layer_0/conv_kernel_0&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 87654321\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 235\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;conv_layer_0/conv_kernel_0/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;conv_layer_0/conv_kernel_0/Initializer/random_uniform/max&quot;\\n  input: &quot;conv_layer_0/conv_kernel_0/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@conv_layer_0/conv_kernel_0&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;conv_layer_0/conv_kernel_0/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;conv_layer_0/conv_kernel_0/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;conv_layer_0/conv_kernel_0/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@conv_layer_0/conv_kernel_0&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;conv_layer_0/conv_kernel_0/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;conv_layer_0/conv_kernel_0/Initializer/random_uniform/mul&quot;\\n  input: &quot;conv_layer_0/conv_kernel_0/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@conv_layer_0/conv_kernel_0&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;conv_layer_0/conv_kernel_0&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@conv_layer_0/conv_kernel_0&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 5\\n        }\\n        dim {\\n          size: 5\\n        }\\n        dim {\\n          size: 3\\n        }\\n        dim {\\n          size: 6\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;conv_layer_0/conv_kernel_0/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;conv_layer_0/conv_kernel_0&quot;\\n  input: &quot;conv_layer_0/conv_kernel_0/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@conv_layer_0/conv_kernel_0&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;conv_layer_0/conv_kernel_0/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;conv_layer_0/conv_kernel_0&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@conv_layer_0/conv_kernel_0&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;conv_layer_0/conv_bias/conv_bias_0/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@conv_layer_0/conv_bias/conv_bias_0&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 6\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;conv_layer_0/conv_bias/conv_bias_0/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@conv_layer_0/conv_bias/conv_bias_0&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.7071067690849304\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;conv_layer_0/conv_bias/conv_bias_0/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@conv_layer_0/conv_bias/conv_bias_0&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.7071067690849304\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;conv_layer_0/conv_bias/conv_bias_0/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;conv_layer_0/conv_bias/conv_bias_0/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@conv_layer_0/conv_bias/conv_bias_0&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 87654321\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 235\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;conv_layer_0/conv_bias/conv_bias_0/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;conv_layer_0/conv_bias/conv_bias_0/Initializer/random_uniform/max&quot;\\n  input: &quot;conv_layer_0/conv_bias/conv_bias_0/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@conv_layer_0/conv_bias/conv_bias_0&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;conv_layer_0/conv_bias/conv_bias_0/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;conv_layer_0/conv_bias/conv_bias_0/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;conv_layer_0/conv_bias/conv_bias_0/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@conv_layer_0/conv_bias/conv_bias_0&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;conv_layer_0/conv_bias/conv_bias_0/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;conv_layer_0/conv_bias/conv_bias_0/Initializer/random_uniform/mul&quot;\\n  input: &quot;conv_layer_0/conv_bias/conv_bias_0/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@conv_layer_0/conv_bias/conv_bias_0&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;conv_layer_0/conv_bias/conv_bias_0&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@conv_layer_0/conv_bias/conv_bias_0&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 6\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;conv_layer_0/conv_bias/conv_bias_0/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;conv_layer_0/conv_bias/conv_bias_0&quot;\\n  input: &quot;conv_layer_0/conv_bias/conv_bias_0/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@conv_layer_0/conv_bias/conv_bias_0&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;conv_layer_0/conv_bias/conv_bias_0/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;conv_layer_0/conv_bias/conv_bias_0&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@conv_layer_0/conv_bias/conv_bias_0&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;conv_layer_0/Conv2D&quot;\\n  op: &quot;Conv2D&quot;\\n  input: &quot;inputs/Placeholder&quot;\\n  input: &quot;conv_layer_0/conv_kernel_0/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dilations&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;conv_layer_0/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;conv_layer_0/Conv2D&quot;\\n  input: &quot;conv_layer_0/conv_bias/conv_bias_0/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;conv_layer_0/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;conv_layer_0/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;conv_layer_0/conv_layer/0/kernel/tag&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;conv_layer_0/conv_layer/0/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;conv_layer_0/conv_layer/0/kernel&quot;\\n  op: &quot;HistogramSummary&quot;\\n  input: &quot;conv_layer_0/conv_layer/0/kernel/tag&quot;\\n  input: &quot;conv_layer_0/conv_kernel_0/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;conv_layer_0/conv_layer/0/bias/tag&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;conv_layer_0/conv_layer/0/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;conv_layer_0/conv_layer/0/bias&quot;\\n  op: &quot;HistogramSummary&quot;\\n  input: &quot;conv_layer_0/conv_layer/0/bias/tag&quot;\\n  input: &quot;conv_layer_0/conv_bias/conv_bias_0/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;max_pooling/MaxPool&quot;\\n  op: &quot;MaxPool&quot;\\n  input: &quot;conv_layer_0/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;ksize&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 2\\n        i: 2\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;VALID&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 2\\n        i: 2\\n        i: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\377\\\\377\\\\377\\\\377\\\\000\\\\006\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;max_pooling/MaxPool&quot;\\n  input: &quot;Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_0/fc_kernel_0/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_0/fc_kernel_0&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\006\\\\000\\\\000T\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_0/fc_kernel_0/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_0/fc_kernel_0&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.06085806339979172\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_0/fc_kernel_0/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_0/fc_kernel_0&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.06085806339979172\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_0/fc_kernel_0/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;fc_layer_0/fc_kernel_0/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_0/fc_kernel_0&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 87654321\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 235\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_0/fc_kernel_0/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;fc_layer_0/fc_kernel_0/Initializer/random_uniform/max&quot;\\n  input: &quot;fc_layer_0/fc_kernel_0/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_0/fc_kernel_0&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_0/fc_kernel_0/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;fc_layer_0/fc_kernel_0/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;fc_layer_0/fc_kernel_0/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_0/fc_kernel_0&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_0/fc_kernel_0/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;fc_layer_0/fc_kernel_0/Initializer/random_uniform/mul&quot;\\n  input: &quot;fc_layer_0/fc_kernel_0/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_0/fc_kernel_0&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_0/fc_kernel_0&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_0/fc_kernel_0&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1536\\n        }\\n        dim {\\n          size: 84\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_0/fc_kernel_0/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;fc_layer_0/fc_kernel_0&quot;\\n  input: &quot;fc_layer_0/fc_kernel_0/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_0/fc_kernel_0&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_0/fc_kernel_0/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;fc_layer_0/fc_kernel_0&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_0/fc_kernel_0&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_0/fc_kernel/fc_bias_0/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_0/fc_kernel/fc_bias_0&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 84\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_0/fc_kernel/fc_bias_0/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_0/fc_kernel/fc_bias_0&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.18898223340511322\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_0/fc_kernel/fc_bias_0/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_0/fc_kernel/fc_bias_0&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.18898223340511322\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_0/fc_kernel/fc_bias_0/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;fc_layer_0/fc_kernel/fc_bias_0/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_0/fc_kernel/fc_bias_0&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 87654321\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 235\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_0/fc_kernel/fc_bias_0/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;fc_layer_0/fc_kernel/fc_bias_0/Initializer/random_uniform/max&quot;\\n  input: &quot;fc_layer_0/fc_kernel/fc_bias_0/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_0/fc_kernel/fc_bias_0&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_0/fc_kernel/fc_bias_0/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;fc_layer_0/fc_kernel/fc_bias_0/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;fc_layer_0/fc_kernel/fc_bias_0/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_0/fc_kernel/fc_bias_0&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_0/fc_kernel/fc_bias_0/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;fc_layer_0/fc_kernel/fc_bias_0/Initializer/random_uniform/mul&quot;\\n  input: &quot;fc_layer_0/fc_kernel/fc_bias_0/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_0/fc_kernel/fc_bias_0&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_0/fc_kernel/fc_bias_0&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_0/fc_kernel/fc_bias_0&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 84\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_0/fc_kernel/fc_bias_0/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;fc_layer_0/fc_kernel/fc_bias_0&quot;\\n  input: &quot;fc_layer_0/fc_kernel/fc_bias_0/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_0/fc_kernel/fc_bias_0&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_0/fc_kernel/fc_bias_0/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;fc_layer_0/fc_kernel/fc_bias_0&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_0/fc_kernel/fc_bias_0&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_0/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Reshape&quot;\\n  input: &quot;fc_layer_0/fc_kernel_0/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_0/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;fc_layer_0/MatMul&quot;\\n  input: &quot;fc_layer_0/fc_kernel/fc_bias_0/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_0/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;fc_layer_0/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_0/fc_layer/0/kernel/tag&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;fc_layer_0/fc_layer/0/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_0/fc_layer/0/kernel&quot;\\n  op: &quot;HistogramSummary&quot;\\n  input: &quot;fc_layer_0/fc_layer/0/kernel/tag&quot;\\n  input: &quot;fc_layer_0/fc_kernel_0/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_0/fc_layer/0/bias/tag&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;fc_layer_0/fc_layer/0/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_0/fc_layer/0/bias&quot;\\n  op: &quot;HistogramSummary&quot;\\n  input: &quot;fc_layer_0/fc_layer/0/bias/tag&quot;\\n  input: &quot;fc_layer_0/fc_kernel/fc_bias_0/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_1/fc_kernel_1/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_1/fc_kernel_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;T\\\\000\\\\000\\\\000\\\\n\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_1/fc_kernel_1/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_1/fc_kernel_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.2526455819606781\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_1/fc_kernel_1/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_1/fc_kernel_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.2526455819606781\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_1/fc_kernel_1/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;fc_layer_1/fc_kernel_1/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_1/fc_kernel_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 87654321\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 235\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_1/fc_kernel_1/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;fc_layer_1/fc_kernel_1/Initializer/random_uniform/max&quot;\\n  input: &quot;fc_layer_1/fc_kernel_1/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_1/fc_kernel_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_1/fc_kernel_1/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;fc_layer_1/fc_kernel_1/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;fc_layer_1/fc_kernel_1/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_1/fc_kernel_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_1/fc_kernel_1/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;fc_layer_1/fc_kernel_1/Initializer/random_uniform/mul&quot;\\n  input: &quot;fc_layer_1/fc_kernel_1/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_1/fc_kernel_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_1/fc_kernel_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_1/fc_kernel_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 84\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_1/fc_kernel_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;fc_layer_1/fc_kernel_1&quot;\\n  input: &quot;fc_layer_1/fc_kernel_1/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_1/fc_kernel_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_1/fc_kernel_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;fc_layer_1/fc_kernel_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_1/fc_kernel_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_1/fc_kernel/fc_bias_1/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_1/fc_kernel/fc_bias_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 10\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_1/fc_kernel/fc_bias_1/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_1/fc_kernel/fc_bias_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.547722578048706\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_1/fc_kernel/fc_bias_1/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_1/fc_kernel/fc_bias_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.547722578048706\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_1/fc_kernel/fc_bias_1/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;fc_layer_1/fc_kernel/fc_bias_1/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_1/fc_kernel/fc_bias_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 87654321\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 235\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_1/fc_kernel/fc_bias_1/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;fc_layer_1/fc_kernel/fc_bias_1/Initializer/random_uniform/max&quot;\\n  input: &quot;fc_layer_1/fc_kernel/fc_bias_1/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_1/fc_kernel/fc_bias_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_1/fc_kernel/fc_bias_1/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;fc_layer_1/fc_kernel/fc_bias_1/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;fc_layer_1/fc_kernel/fc_bias_1/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_1/fc_kernel/fc_bias_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_1/fc_kernel/fc_bias_1/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;fc_layer_1/fc_kernel/fc_bias_1/Initializer/random_uniform/mul&quot;\\n  input: &quot;fc_layer_1/fc_kernel/fc_bias_1/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_1/fc_kernel/fc_bias_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_1/fc_kernel/fc_bias_1&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_1/fc_kernel/fc_bias_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_1/fc_kernel/fc_bias_1/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;fc_layer_1/fc_kernel/fc_bias_1&quot;\\n  input: &quot;fc_layer_1/fc_kernel/fc_bias_1/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_1/fc_kernel/fc_bias_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_1/fc_kernel/fc_bias_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;fc_layer_1/fc_kernel/fc_bias_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_1/fc_kernel/fc_bias_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_1/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;fc_layer_0/Relu&quot;\\n  input: &quot;fc_layer_1/fc_kernel_1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_1/Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;fc_layer_1/MatMul&quot;\\n  input: &quot;fc_layer_1/fc_kernel/fc_bias_1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_1/fc_layer/1/kernel/tag&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;fc_layer_1/fc_layer/1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_1/fc_layer/1/kernel&quot;\\n  op: &quot;HistogramSummary&quot;\\n  input: &quot;fc_layer_1/fc_layer/1/kernel/tag&quot;\\n  input: &quot;fc_layer_1/fc_kernel_1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_1/fc_layer/1/bias/tag&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;fc_layer_1/fc_layer/1/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_1/fc_layer/1/bias&quot;\\n  op: &quot;HistogramSummary&quot;\\n  input: &quot;fc_layer_1/fc_layer/1/bias/tag&quot;\\n  input: &quot;fc_layer_1/fc_kernel/fc_bias_1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/norm/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;fc_layer_0/fc_kernel_0/read&quot;\\n  input: &quot;fc_layer_0/fc_kernel_0/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/norm/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/norm/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;loss/norm/mul&quot;\\n  input: &quot;loss/norm/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/norm/Sqrt&quot;\\n  op: &quot;Sqrt&quot;\\n  input: &quot;loss/norm/Sum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/norm/Squeeze&quot;\\n  op: &quot;Squeeze&quot;\\n  input: &quot;loss/norm/Sqrt&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;squeeze_dims&quot;\\n    value {\\n      list {\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/norm_1/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;fc_layer_1/fc_kernel_1/read&quot;\\n  input: &quot;fc_layer_1/fc_kernel_1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/norm_1/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/norm_1/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;loss/norm_1/mul&quot;\\n  input: &quot;loss/norm_1/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/norm_1/Sqrt&quot;\\n  op: &quot;Sqrt&quot;\\n  input: &quot;loss/norm_1/Sum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/norm_1/Squeeze&quot;\\n  op: &quot;Squeeze&quot;\\n  input: &quot;loss/norm_1/Sqrt&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;squeeze_dims&quot;\\n    value {\\n      list {\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Rank/packed&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;loss/norm/Squeeze&quot;\\n  input: &quot;loss/norm_1/Squeeze&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Rank&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;loss/range/start&quot;\\n  input: &quot;loss/Rank&quot;\\n  input: &quot;loss/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Sum/input&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;loss/norm/Squeeze&quot;\\n  input: &quot;loss/norm_1/Squeeze&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;loss/Sum/input&quot;\\n  input: &quot;loss/range&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/norm_2/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;conv_layer_0/conv_kernel_0/read&quot;\\n  input: &quot;conv_layer_0/conv_kernel_0/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/norm_2/Sum/reduction_indices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\376\\\\377\\\\377\\\\377\\\\377\\\\377\\\\377\\\\377&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/norm_2/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;loss/norm_2/mul&quot;\\n  input: &quot;loss/norm_2/Sum/reduction_indices&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/norm_2/Sqrt&quot;\\n  op: &quot;Sqrt&quot;\\n  input: &quot;loss/norm_2/Sum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/norm_2/Squeeze&quot;\\n  op: &quot;Squeeze&quot;\\n  input: &quot;loss/norm_2/Sqrt&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;squeeze_dims&quot;\\n    value {\\n      list {\\n        i: -2\\n        i: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;loss/norm_2/Squeeze&quot;\\n  input: &quot;loss/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Rank_1/packed&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;loss/Sum_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Rank_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/range_1/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/range_1/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/range_1&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;loss/range_1/start&quot;\\n  input: &quot;loss/Rank_1&quot;\\n  input: &quot;loss/range_1/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Sum_2/input&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;loss/Sum_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Sum_2&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;loss/Sum_2/input&quot;\\n  input: &quot;loss/range_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;loss/Sum&quot;\\n  input: &quot;loss/Sum_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/one_hot/on_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/one_hot/off_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/one_hot/depth&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 10\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/one_hot&quot;\\n  op: &quot;OneHot&quot;\\n  input: &quot;inputs/Placeholder_1&quot;\\n  input: &quot;loss/one_hot/depth&quot;\\n  input: &quot;loss/one_hot/on_value&quot;\\n  input: &quot;loss/one_hot/off_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;TI&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: -1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/softmax_cross_entropy_with_logits_sg/labels_stop_gradient&quot;\\n  op: &quot;StopGradient&quot;\\n  input: &quot;loss/one_hot&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/softmax_cross_entropy_with_logits_sg/Rank&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/softmax_cross_entropy_with_logits_sg/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;fc_layer_1/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/softmax_cross_entropy_with_logits_sg/Rank_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/softmax_cross_entropy_with_logits_sg/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;fc_layer_1/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/softmax_cross_entropy_with_logits_sg/Sub/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/softmax_cross_entropy_with_logits_sg/Sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;loss/softmax_cross_entropy_with_logits_sg/Rank_1&quot;\\n  input: &quot;loss/softmax_cross_entropy_with_logits_sg/Sub/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/softmax_cross_entropy_with_logits_sg/Slice/begin&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;loss/softmax_cross_entropy_with_logits_sg/Sub&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/softmax_cross_entropy_with_logits_sg/Slice/size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/softmax_cross_entropy_with_logits_sg/Slice&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;loss/softmax_cross_entropy_with_logits_sg/Shape_1&quot;\\n  input: &quot;loss/softmax_cross_entropy_with_logits_sg/Slice/begin&quot;\\n  input: &quot;loss/softmax_cross_entropy_with_logits_sg/Slice/size&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/softmax_cross_entropy_with_logits_sg/concat/values_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/softmax_cross_entropy_with_logits_sg/concat/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/softmax_cross_entropy_with_logits_sg/concat&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;loss/softmax_cross_entropy_with_logits_sg/concat/values_0&quot;\\n  input: &quot;loss/softmax_cross_entropy_with_logits_sg/Slice&quot;\\n  input: &quot;loss/softmax_cross_entropy_with_logits_sg/concat/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/softmax_cross_entropy_with_logits_sg/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;fc_layer_1/Add&quot;\\n  input: &quot;loss/softmax_cross_entropy_with_logits_sg/concat&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/softmax_cross_entropy_with_logits_sg/Rank_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/softmax_cross_entropy_with_logits_sg/Shape_2&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/softmax_cross_entropy_with_logits_sg/labels_stop_gradient&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/softmax_cross_entropy_with_logits_sg/Sub_1/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/softmax_cross_entropy_with_logits_sg/Sub_1&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;loss/softmax_cross_entropy_with_logits_sg/Rank_2&quot;\\n  input: &quot;loss/softmax_cross_entropy_with_logits_sg/Sub_1/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/softmax_cross_entropy_with_logits_sg/Slice_1/begin&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;loss/softmax_cross_entropy_with_logits_sg/Sub_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/softmax_cross_entropy_with_logits_sg/Slice_1/size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/softmax_cross_entropy_with_logits_sg/Slice_1&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;loss/softmax_cross_entropy_with_logits_sg/Shape_2&quot;\\n  input: &quot;loss/softmax_cross_entropy_with_logits_sg/Slice_1/begin&quot;\\n  input: &quot;loss/softmax_cross_entropy_with_logits_sg/Slice_1/size&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/softmax_cross_entropy_with_logits_sg/concat_1/values_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/softmax_cross_entropy_with_logits_sg/concat_1/axis&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/softmax_cross_entropy_with_logits_sg/concat_1&quot;\\n  op: &quot;ConcatV2&quot;\\n  input: &quot;loss/softmax_cross_entropy_with_logits_sg/concat_1/values_0&quot;\\n  input: &quot;loss/softmax_cross_entropy_with_logits_sg/Slice_1&quot;\\n  input: &quot;loss/softmax_cross_entropy_with_logits_sg/concat_1/axis&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/softmax_cross_entropy_with_logits_sg/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;loss/softmax_cross_entropy_with_logits_sg/labels_stop_gradient&quot;\\n  input: &quot;loss/softmax_cross_entropy_with_logits_sg/concat_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/softmax_cross_entropy_with_logits_sg&quot;\\n  op: &quot;SoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;loss/softmax_cross_entropy_with_logits_sg/Reshape&quot;\\n  input: &quot;loss/softmax_cross_entropy_with_logits_sg/Reshape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/softmax_cross_entropy_with_logits_sg/Sub_2/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/softmax_cross_entropy_with_logits_sg/Sub_2&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;loss/softmax_cross_entropy_with_logits_sg/Rank&quot;\\n  input: &quot;loss/softmax_cross_entropy_with_logits_sg/Sub_2/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/softmax_cross_entropy_with_logits_sg/Slice_2/begin&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/softmax_cross_entropy_with_logits_sg/Slice_2/size&quot;\\n  op: &quot;Pack&quot;\\n  input: &quot;loss/softmax_cross_entropy_with_logits_sg/Sub_2&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/softmax_cross_entropy_with_logits_sg/Slice_2&quot;\\n  op: &quot;Slice&quot;\\n  input: &quot;loss/softmax_cross_entropy_with_logits_sg/Shape&quot;\\n  input: &quot;loss/softmax_cross_entropy_with_logits_sg/Slice_2/begin&quot;\\n  input: &quot;loss/softmax_cross_entropy_with_logits_sg/Slice_2/size&quot;\\n  attr {\\n    key: &quot;Index&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/softmax_cross_entropy_with_logits_sg/Reshape_2&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;loss/softmax_cross_entropy_with_logits_sg&quot;\\n  input: &quot;loss/softmax_cross_entropy_with_logits_sg/Slice_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/cross_entropy&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;loss/softmax_cross_entropy_with_logits_sg/Reshape_2&quot;\\n  input: &quot;loss/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/mul/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.009999999776482582\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;loss/mul/x&quot;\\n  input: &quot;loss/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/loss&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;loss/cross_entropy&quot;\\n  input: &quot;loss/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/LeNet_loss/tags&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;loss/LeNet_loss&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/LeNet_loss&quot;\\n  op: &quot;ScalarSummary&quot;\\n  input: &quot;loss/LeNet_loss/tags&quot;\\n  input: &quot;loss/loss&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/grad_ys_0&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;train_step/gradients/Shape&quot;\\n  input: &quot;train_step/gradients/grad_ys_0&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/loss_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train_step/gradients/Fill&quot;\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/loss_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train_step/gradients/Fill&quot;\\n  input: &quot;^train_step/gradients/loss/loss_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/Fill&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/loss_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train_step/gradients/Fill&quot;\\n  input: &quot;^train_step/gradients/loss/loss_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/Fill&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/cross_entropy_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/cross_entropy_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train_step/gradients/loss/loss_grad/tuple/control_dependency&quot;\\n  input: &quot;train_step/gradients/loss/cross_entropy_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/cross_entropy_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/softmax_cross_entropy_with_logits_sg/Reshape_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/cross_entropy_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;train_step/gradients/loss/cross_entropy_grad/Reshape&quot;\\n  input: &quot;train_step/gradients/loss/cross_entropy_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/cross_entropy_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/softmax_cross_entropy_with_logits_sg/Reshape_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/cross_entropy_grad/Shape_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/cross_entropy_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/cross_entropy_grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;train_step/gradients/loss/cross_entropy_grad/Shape_1&quot;\\n  input: &quot;train_step/gradients/loss/cross_entropy_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/cross_entropy_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/cross_entropy_grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;train_step/gradients/loss/cross_entropy_grad/Shape_2&quot;\\n  input: &quot;train_step/gradients/loss/cross_entropy_grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/cross_entropy_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/cross_entropy_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;train_step/gradients/loss/cross_entropy_grad/Prod_1&quot;\\n  input: &quot;train_step/gradients/loss/cross_entropy_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/cross_entropy_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;train_step/gradients/loss/cross_entropy_grad/Prod&quot;\\n  input: &quot;train_step/gradients/loss/cross_entropy_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/cross_entropy_grad/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;train_step/gradients/loss/cross_entropy_grad/floordiv&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/cross_entropy_grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;train_step/gradients/loss/cross_entropy_grad/Tile&quot;\\n  input: &quot;train_step/gradients/loss/cross_entropy_grad/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/mul_grad/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train_step/gradients/loss/loss_grad/tuple/control_dependency_1&quot;\\n  input: &quot;loss/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/mul_grad/Mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train_step/gradients/loss/loss_grad/tuple/control_dependency_1&quot;\\n  input: &quot;loss/mul/x&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train_step/gradients/loss/mul_grad/Mul&quot;\\n  input: &quot;^train_step/gradients/loss/mul_grad/Mul_1&quot;\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train_step/gradients/loss/mul_grad/Mul&quot;\\n  input: &quot;^train_step/gradients/loss/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/loss/mul_grad/Mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train_step/gradients/loss/mul_grad/Mul_1&quot;\\n  input: &quot;^train_step/gradients/loss/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/loss/mul_grad/Mul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/softmax_cross_entropy_with_logits_sg/Reshape_2_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/softmax_cross_entropy_with_logits_sg&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/softmax_cross_entropy_with_logits_sg/Reshape_2_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train_step/gradients/loss/cross_entropy_grad/truediv&quot;\\n  input: &quot;train_step/gradients/loss/softmax_cross_entropy_with_logits_sg/Reshape_2_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train_step/gradients/loss/mul_grad/tuple/control_dependency_1&quot;\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train_step/gradients/loss/mul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^train_step/gradients/loss/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/loss/mul_grad/Mul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train_step/gradients/loss/mul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;^train_step/gradients/loss/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/loss/mul_grad/Mul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;loss/softmax_cross_entropy_with_logits_sg:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/softmax_cross_entropy_with_logits_sg_grad/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/softmax_cross_entropy_with_logits_sg_grad/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;train_step/gradients/loss/softmax_cross_entropy_with_logits_sg/Reshape_2_grad/Reshape&quot;\\n  input: &quot;train_step/gradients/loss/softmax_cross_entropy_with_logits_sg_grad/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/softmax_cross_entropy_with_logits_sg_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train_step/gradients/loss/softmax_cross_entropy_with_logits_sg_grad/ExpandDims&quot;\\n  input: &quot;loss/softmax_cross_entropy_with_logits_sg:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/softmax_cross_entropy_with_logits_sg_grad/LogSoftmax&quot;\\n  op: &quot;LogSoftmax&quot;\\n  input: &quot;loss/softmax_cross_entropy_with_logits_sg/Reshape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/softmax_cross_entropy_with_logits_sg_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;train_step/gradients/loss/softmax_cross_entropy_with_logits_sg_grad/LogSoftmax&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/softmax_cross_entropy_with_logits_sg_grad/ExpandDims_1/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/softmax_cross_entropy_with_logits_sg_grad/ExpandDims_1&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;train_step/gradients/loss/softmax_cross_entropy_with_logits_sg/Reshape_2_grad/Reshape&quot;\\n  input: &quot;train_step/gradients/loss/softmax_cross_entropy_with_logits_sg_grad/ExpandDims_1/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/softmax_cross_entropy_with_logits_sg_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train_step/gradients/loss/softmax_cross_entropy_with_logits_sg_grad/ExpandDims_1&quot;\\n  input: &quot;train_step/gradients/loss/softmax_cross_entropy_with_logits_sg_grad/Neg&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/softmax_cross_entropy_with_logits_sg_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train_step/gradients/loss/softmax_cross_entropy_with_logits_sg_grad/mul&quot;\\n  input: &quot;^train_step/gradients/loss/softmax_cross_entropy_with_logits_sg_grad/mul_1&quot;\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/softmax_cross_entropy_with_logits_sg_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train_step/gradients/loss/softmax_cross_entropy_with_logits_sg_grad/mul&quot;\\n  input: &quot;^train_step/gradients/loss/softmax_cross_entropy_with_logits_sg_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/loss/softmax_cross_entropy_with_logits_sg_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/softmax_cross_entropy_with_logits_sg_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train_step/gradients/loss/softmax_cross_entropy_with_logits_sg_grad/mul_1&quot;\\n  input: &quot;^train_step/gradients/loss/softmax_cross_entropy_with_logits_sg_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/loss/softmax_cross_entropy_with_logits_sg_grad/mul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/Sum_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/Sum_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train_step/gradients/loss/add_grad/tuple/control_dependency&quot;\\n  input: &quot;train_step/gradients/loss/Sum_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/Sum_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/Sum_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;train_step/gradients/loss/Sum_grad/Reshape&quot;\\n  input: &quot;train_step/gradients/loss/Sum_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/Sum_2_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/Sum_2_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train_step/gradients/loss/add_grad/tuple/control_dependency_1&quot;\\n  input: &quot;train_step/gradients/loss/Sum_2_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/Sum_2_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/Sum_2_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;train_step/gradients/loss/Sum_2_grad/Reshape&quot;\\n  input: &quot;train_step/gradients/loss/Sum_2_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/softmax_cross_entropy_with_logits_sg/Reshape_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;fc_layer_1/Add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/softmax_cross_entropy_with_logits_sg/Reshape_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train_step/gradients/loss/softmax_cross_entropy_with_logits_sg_grad/tuple/control_dependency&quot;\\n  input: &quot;train_step/gradients/loss/softmax_cross_entropy_with_logits_sg/Reshape_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/Sum/input_grad/unstack&quot;\\n  op: &quot;Unpack&quot;\\n  input: &quot;train_step/gradients/loss/Sum_grad/Tile&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;num&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/Sum/input_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train_step/gradients/loss/Sum/input_grad/unstack&quot;\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/Sum/input_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train_step/gradients/loss/Sum/input_grad/unstack&quot;\\n  input: &quot;^train_step/gradients/loss/Sum/input_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/loss/Sum/input_grad/unstack&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/Sum/input_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train_step/gradients/loss/Sum/input_grad/unstack:1&quot;\\n  input: &quot;^train_step/gradients/loss/Sum/input_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/loss/Sum/input_grad/unstack&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/Sum_2/input_grad/unstack&quot;\\n  op: &quot;Unpack&quot;\\n  input: &quot;train_step/gradients/loss/Sum_2_grad/Tile&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;axis&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;num&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/fc_layer_1/Add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;fc_layer_1/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/fc_layer_1/Add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 10\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/fc_layer_1/Add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train_step/gradients/fc_layer_1/Add_grad/Shape&quot;\\n  input: &quot;train_step/gradients/fc_layer_1/Add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/fc_layer_1/Add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train_step/gradients/loss/softmax_cross_entropy_with_logits_sg/Reshape_grad/Reshape&quot;\\n  input: &quot;train_step/gradients/fc_layer_1/Add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/fc_layer_1/Add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train_step/gradients/fc_layer_1/Add_grad/Sum&quot;\\n  input: &quot;train_step/gradients/fc_layer_1/Add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/fc_layer_1/Add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train_step/gradients/loss/softmax_cross_entropy_with_logits_sg/Reshape_grad/Reshape&quot;\\n  input: &quot;train_step/gradients/fc_layer_1/Add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/fc_layer_1/Add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train_step/gradients/fc_layer_1/Add_grad/Sum_1&quot;\\n  input: &quot;train_step/gradients/fc_layer_1/Add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/fc_layer_1/Add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train_step/gradients/fc_layer_1/Add_grad/Reshape&quot;\\n  input: &quot;^train_step/gradients/fc_layer_1/Add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train_step/gradients/fc_layer_1/Add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train_step/gradients/fc_layer_1/Add_grad/Reshape&quot;\\n  input: &quot;^train_step/gradients/fc_layer_1/Add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/fc_layer_1/Add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/fc_layer_1/Add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train_step/gradients/fc_layer_1/Add_grad/Reshape_1&quot;\\n  input: &quot;^train_step/gradients/fc_layer_1/Add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/fc_layer_1/Add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm/Squeeze_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm/Squeeze_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train_step/gradients/loss/Sum/input_grad/tuple/control_dependency&quot;\\n  input: &quot;train_step/gradients/loss/norm/Squeeze_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm_1/Squeeze_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm_1/Squeeze_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train_step/gradients/loss/Sum/input_grad/tuple/control_dependency_1&quot;\\n  input: &quot;train_step/gradients/loss/norm_1/Squeeze_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/Sum_1_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/Sum_1_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train_step/gradients/loss/Sum_2/input_grad/unstack&quot;\\n  input: &quot;train_step/gradients/loss/Sum_1_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/Sum_1_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\005\\\\000\\\\000\\\\000\\\\005\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/Sum_1_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;train_step/gradients/loss/Sum_1_grad/Reshape&quot;\\n  input: &quot;train_step/gradients/loss/Sum_1_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/fc_layer_1/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;train_step/gradients/fc_layer_1/Add_grad/tuple/control_dependency&quot;\\n  input: &quot;fc_layer_1/fc_kernel_1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/fc_layer_1/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;fc_layer_0/Relu&quot;\\n  input: &quot;train_step/gradients/fc_layer_1/Add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/fc_layer_1/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train_step/gradients/fc_layer_1/MatMul_grad/MatMul&quot;\\n  input: &quot;^train_step/gradients/fc_layer_1/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;train_step/gradients/fc_layer_1/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train_step/gradients/fc_layer_1/MatMul_grad/MatMul&quot;\\n  input: &quot;^train_step/gradients/fc_layer_1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/fc_layer_1/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/fc_layer_1/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train_step/gradients/fc_layer_1/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^train_step/gradients/fc_layer_1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/fc_layer_1/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm/Sqrt_grad/SqrtGrad&quot;\\n  op: &quot;SqrtGrad&quot;\\n  input: &quot;loss/norm/Sqrt&quot;\\n  input: &quot;train_step/gradients/loss/norm/Squeeze_grad/Reshape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm_1/Sqrt_grad/SqrtGrad&quot;\\n  op: &quot;SqrtGrad&quot;\\n  input: &quot;loss/norm_1/Sqrt&quot;\\n  input: &quot;train_step/gradients/loss/norm_1/Squeeze_grad/Reshape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm_2/Squeeze_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\005\\\\000\\\\000\\\\000\\\\005\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm_2/Squeeze_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train_step/gradients/loss/Sum_1_grad/Tile&quot;\\n  input: &quot;train_step/gradients/loss/norm_2/Squeeze_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/fc_layer_0/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;train_step/gradients/fc_layer_1/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;fc_layer_0/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm/Sum_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm/Sum_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train_step/gradients/loss/norm/Sqrt_grad/SqrtGrad&quot;\\n  input: &quot;train_step/gradients/loss/norm/Sum_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm/Sum_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\006\\\\000\\\\000T\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm/Sum_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;train_step/gradients/loss/norm/Sum_grad/Reshape&quot;\\n  input: &quot;train_step/gradients/loss/norm/Sum_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm_1/Sum_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm_1/Sum_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train_step/gradients/loss/norm_1/Sqrt_grad/SqrtGrad&quot;\\n  input: &quot;train_step/gradients/loss/norm_1/Sum_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm_1/Sum_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;T\\\\000\\\\000\\\\000\\\\n\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm_1/Sum_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;train_step/gradients/loss/norm_1/Sum_grad/Reshape&quot;\\n  input: &quot;train_step/gradients/loss/norm_1/Sum_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm_2/Sqrt_grad/SqrtGrad&quot;\\n  op: &quot;SqrtGrad&quot;\\n  input: &quot;loss/norm_2/Sqrt&quot;\\n  input: &quot;train_step/gradients/loss/norm_2/Squeeze_grad/Reshape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/fc_layer_0/Add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;fc_layer_0/MatMul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/fc_layer_0/Add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 84\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/fc_layer_0/Add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train_step/gradients/fc_layer_0/Add_grad/Shape&quot;\\n  input: &quot;train_step/gradients/fc_layer_0/Add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/fc_layer_0/Add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train_step/gradients/fc_layer_0/Relu_grad/ReluGrad&quot;\\n  input: &quot;train_step/gradients/fc_layer_0/Add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/fc_layer_0/Add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train_step/gradients/fc_layer_0/Add_grad/Sum&quot;\\n  input: &quot;train_step/gradients/fc_layer_0/Add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/fc_layer_0/Add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train_step/gradients/fc_layer_0/Relu_grad/ReluGrad&quot;\\n  input: &quot;train_step/gradients/fc_layer_0/Add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/fc_layer_0/Add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train_step/gradients/fc_layer_0/Add_grad/Sum_1&quot;\\n  input: &quot;train_step/gradients/fc_layer_0/Add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/fc_layer_0/Add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train_step/gradients/fc_layer_0/Add_grad/Reshape&quot;\\n  input: &quot;^train_step/gradients/fc_layer_0/Add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train_step/gradients/fc_layer_0/Add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train_step/gradients/fc_layer_0/Add_grad/Reshape&quot;\\n  input: &quot;^train_step/gradients/fc_layer_0/Add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/fc_layer_0/Add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/fc_layer_0/Add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train_step/gradients/fc_layer_0/Add_grad/Reshape_1&quot;\\n  input: &quot;^train_step/gradients/fc_layer_0/Add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/fc_layer_0/Add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm/mul_grad/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train_step/gradients/loss/norm/Sum_grad/Tile&quot;\\n  input: &quot;fc_layer_0/fc_kernel_0/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm/mul_grad/Mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train_step/gradients/loss/norm/Sum_grad/Tile&quot;\\n  input: &quot;fc_layer_0/fc_kernel_0/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm/mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train_step/gradients/loss/norm/mul_grad/Mul&quot;\\n  input: &quot;^train_step/gradients/loss/norm/mul_grad/Mul_1&quot;\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm/mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train_step/gradients/loss/norm/mul_grad/Mul&quot;\\n  input: &quot;^train_step/gradients/loss/norm/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/loss/norm/mul_grad/Mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm/mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train_step/gradients/loss/norm/mul_grad/Mul_1&quot;\\n  input: &quot;^train_step/gradients/loss/norm/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/loss/norm/mul_grad/Mul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm_1/mul_grad/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train_step/gradients/loss/norm_1/Sum_grad/Tile&quot;\\n  input: &quot;fc_layer_1/fc_kernel_1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm_1/mul_grad/Mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train_step/gradients/loss/norm_1/Sum_grad/Tile&quot;\\n  input: &quot;fc_layer_1/fc_kernel_1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm_1/mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train_step/gradients/loss/norm_1/mul_grad/Mul&quot;\\n  input: &quot;^train_step/gradients/loss/norm_1/mul_grad/Mul_1&quot;\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm_1/mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train_step/gradients/loss/norm_1/mul_grad/Mul&quot;\\n  input: &quot;^train_step/gradients/loss/norm_1/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/loss/norm_1/mul_grad/Mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm_1/mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train_step/gradients/loss/norm_1/mul_grad/Mul_1&quot;\\n  input: &quot;^train_step/gradients/loss/norm_1/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/loss/norm_1/mul_grad/Mul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm_2/Sum_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\005\\\\000\\\\000\\\\000\\\\005\\\\000\\\\000\\\\000\\\\003\\\\000\\\\000\\\\000\\\\006\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm_2/Sum_grad/Size&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/loss/norm_2/Sum_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 4\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm_2/Sum_grad/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;loss/norm_2/Sum/reduction_indices&quot;\\n  input: &quot;train_step/gradients/loss/norm_2/Sum_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/loss/norm_2/Sum_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm_2/Sum_grad/mod&quot;\\n  op: &quot;FloorMod&quot;\\n  input: &quot;train_step/gradients/loss/norm_2/Sum_grad/add&quot;\\n  input: &quot;train_step/gradients/loss/norm_2/Sum_grad/Size&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/loss/norm_2/Sum_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm_2/Sum_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/loss/norm_2/Sum_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm_2/Sum_grad/range/start&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/loss/norm_2/Sum_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm_2/Sum_grad/range/delta&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/loss/norm_2/Sum_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm_2/Sum_grad/range&quot;\\n  op: &quot;Range&quot;\\n  input: &quot;train_step/gradients/loss/norm_2/Sum_grad/range/start&quot;\\n  input: &quot;train_step/gradients/loss/norm_2/Sum_grad/Size&quot;\\n  input: &quot;train_step/gradients/loss/norm_2/Sum_grad/range/delta&quot;\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/loss/norm_2/Sum_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm_2/Sum_grad/Fill/value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/loss/norm_2/Sum_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm_2/Sum_grad/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;train_step/gradients/loss/norm_2/Sum_grad/Shape_1&quot;\\n  input: &quot;train_step/gradients/loss/norm_2/Sum_grad/Fill/value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/loss/norm_2/Sum_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;index_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm_2/Sum_grad/DynamicStitch&quot;\\n  op: &quot;DynamicStitch&quot;\\n  input: &quot;train_step/gradients/loss/norm_2/Sum_grad/range&quot;\\n  input: &quot;train_step/gradients/loss/norm_2/Sum_grad/mod&quot;\\n  input: &quot;train_step/gradients/loss/norm_2/Sum_grad/Shape&quot;\\n  input: &quot;train_step/gradients/loss/norm_2/Sum_grad/Fill&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/loss/norm_2/Sum_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm_2/Sum_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/loss/norm_2/Sum_grad/Shape&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm_2/Sum_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;train_step/gradients/loss/norm_2/Sum_grad/DynamicStitch&quot;\\n  input: &quot;train_step/gradients/loss/norm_2/Sum_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/loss/norm_2/Sum_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm_2/Sum_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;train_step/gradients/loss/norm_2/Sum_grad/Shape&quot;\\n  input: &quot;train_step/gradients/loss/norm_2/Sum_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/loss/norm_2/Sum_grad/Shape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm_2/Sum_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train_step/gradients/loss/norm_2/Sqrt_grad/SqrtGrad&quot;\\n  input: &quot;train_step/gradients/loss/norm_2/Sum_grad/DynamicStitch&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm_2/Sum_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;train_step/gradients/loss/norm_2/Sum_grad/Reshape&quot;\\n  input: &quot;train_step/gradients/loss/norm_2/Sum_grad/floordiv&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/fc_layer_0/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;train_step/gradients/fc_layer_0/Add_grad/tuple/control_dependency&quot;\\n  input: &quot;fc_layer_0/fc_kernel_0/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/fc_layer_0/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Reshape&quot;\\n  input: &quot;train_step/gradients/fc_layer_0/Add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/fc_layer_0/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train_step/gradients/fc_layer_0/MatMul_grad/MatMul&quot;\\n  input: &quot;^train_step/gradients/fc_layer_0/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;train_step/gradients/fc_layer_0/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train_step/gradients/fc_layer_0/MatMul_grad/MatMul&quot;\\n  input: &quot;^train_step/gradients/fc_layer_0/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/fc_layer_0/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/fc_layer_0/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train_step/gradients/fc_layer_0/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^train_step/gradients/fc_layer_0/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/fc_layer_0/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/AddN&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;train_step/gradients/fc_layer_1/MatMul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;train_step/gradients/loss/norm_1/mul_grad/tuple/control_dependency&quot;\\n  input: &quot;train_step/gradients/loss/norm_1/mul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 3\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/fc_layer_1/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm_2/mul_grad/Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train_step/gradients/loss/norm_2/Sum_grad/Tile&quot;\\n  input: &quot;conv_layer_0/conv_kernel_0/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm_2/mul_grad/Mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;train_step/gradients/loss/norm_2/Sum_grad/Tile&quot;\\n  input: &quot;conv_layer_0/conv_kernel_0/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm_2/mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train_step/gradients/loss/norm_2/mul_grad/Mul&quot;\\n  input: &quot;^train_step/gradients/loss/norm_2/mul_grad/Mul_1&quot;\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm_2/mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train_step/gradients/loss/norm_2/mul_grad/Mul&quot;\\n  input: &quot;^train_step/gradients/loss/norm_2/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/loss/norm_2/mul_grad/Mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/loss/norm_2/mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train_step/gradients/loss/norm_2/mul_grad/Mul_1&quot;\\n  input: &quot;^train_step/gradients/loss/norm_2/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/loss/norm_2/mul_grad/Mul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/Reshape_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;max_pooling/MaxPool&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/Reshape_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train_step/gradients/fc_layer_0/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;train_step/gradients/Reshape_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/AddN_1&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;train_step/gradients/loss/norm/mul_grad/tuple/control_dependency&quot;\\n  input: &quot;train_step/gradients/loss/norm/mul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;train_step/gradients/fc_layer_0/MatMul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 3\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/loss/norm/mul_grad/Mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/max_pooling/MaxPool_grad/MaxPoolGrad&quot;\\n  op: &quot;MaxPoolGrad&quot;\\n  input: &quot;conv_layer_0/Relu&quot;\\n  input: &quot;max_pooling/MaxPool&quot;\\n  input: &quot;train_step/gradients/Reshape_grad/Reshape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;ksize&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 2\\n        i: 2\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;VALID&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 2\\n        i: 2\\n        i: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/conv_layer_0/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;train_step/gradients/max_pooling/MaxPool_grad/MaxPoolGrad&quot;\\n  input: &quot;conv_layer_0/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/conv_layer_0/add_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;conv_layer_0/Conv2D&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/conv_layer_0/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 6\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/conv_layer_0/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;train_step/gradients/conv_layer_0/add_grad/Shape&quot;\\n  input: &quot;train_step/gradients/conv_layer_0/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/conv_layer_0/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train_step/gradients/conv_layer_0/Relu_grad/ReluGrad&quot;\\n  input: &quot;train_step/gradients/conv_layer_0/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/conv_layer_0/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train_step/gradients/conv_layer_0/add_grad/Sum&quot;\\n  input: &quot;train_step/gradients/conv_layer_0/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/conv_layer_0/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;train_step/gradients/conv_layer_0/Relu_grad/ReluGrad&quot;\\n  input: &quot;train_step/gradients/conv_layer_0/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/conv_layer_0/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;train_step/gradients/conv_layer_0/add_grad/Sum_1&quot;\\n  input: &quot;train_step/gradients/conv_layer_0/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/conv_layer_0/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train_step/gradients/conv_layer_0/add_grad/Reshape&quot;\\n  input: &quot;^train_step/gradients/conv_layer_0/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;train_step/gradients/conv_layer_0/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train_step/gradients/conv_layer_0/add_grad/Reshape&quot;\\n  input: &quot;^train_step/gradients/conv_layer_0/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/conv_layer_0/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/conv_layer_0/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train_step/gradients/conv_layer_0/add_grad/Reshape_1&quot;\\n  input: &quot;^train_step/gradients/conv_layer_0/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/conv_layer_0/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/conv_layer_0/Conv2D_grad/ShapeN&quot;\\n  op: &quot;ShapeN&quot;\\n  input: &quot;inputs/Placeholder&quot;\\n  input: &quot;conv_layer_0/conv_kernel_0/read&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/conv_layer_0/Conv2D_grad/Conv2DBackpropInput&quot;\\n  op: &quot;Conv2DBackpropInput&quot;\\n  input: &quot;train_step/gradients/conv_layer_0/Conv2D_grad/ShapeN&quot;\\n  input: &quot;conv_layer_0/conv_kernel_0/read&quot;\\n  input: &quot;train_step/gradients/conv_layer_0/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dilations&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/conv_layer_0/Conv2D_grad/Conv2DBackpropFilter&quot;\\n  op: &quot;Conv2DBackpropFilter&quot;\\n  input: &quot;inputs/Placeholder&quot;\\n  input: &quot;train_step/gradients/conv_layer_0/Conv2D_grad/ShapeN:1&quot;\\n  input: &quot;train_step/gradients/conv_layer_0/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dilations&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/conv_layer_0/Conv2D_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train_step/gradients/conv_layer_0/Conv2D_grad/Conv2DBackpropFilter&quot;\\n  input: &quot;^train_step/gradients/conv_layer_0/Conv2D_grad/Conv2DBackpropInput&quot;\\n}\\nnode {\\n  name: &quot;train_step/gradients/conv_layer_0/Conv2D_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train_step/gradients/conv_layer_0/Conv2D_grad/Conv2DBackpropInput&quot;\\n  input: &quot;^train_step/gradients/conv_layer_0/Conv2D_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/conv_layer_0/Conv2D_grad/Conv2DBackpropInput&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/conv_layer_0/Conv2D_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;train_step/gradients/conv_layer_0/Conv2D_grad/Conv2DBackpropFilter&quot;\\n  input: &quot;^train_step/gradients/conv_layer_0/Conv2D_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/conv_layer_0/Conv2D_grad/Conv2DBackpropFilter&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/gradients/AddN_2&quot;\\n  op: &quot;AddN&quot;\\n  input: &quot;train_step/gradients/loss/norm_2/mul_grad/tuple/control_dependency&quot;\\n  input: &quot;train_step/gradients/loss/norm_2/mul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;train_step/gradients/conv_layer_0/Conv2D_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 3\\n    }\\n  }\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@train_step/gradients/loss/norm_2/mul_grad/Mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/GradientDescent/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0010000000474974513\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/GradientDescent/update_conv_layer_0/conv_kernel_0/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;conv_layer_0/conv_kernel_0&quot;\\n  input: &quot;train_step/GradientDescent/learning_rate&quot;\\n  input: &quot;train_step/gradients/AddN_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@conv_layer_0/conv_kernel_0&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/GradientDescent/update_conv_layer_0/conv_bias/conv_bias_0/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;conv_layer_0/conv_bias/conv_bias_0&quot;\\n  input: &quot;train_step/GradientDescent/learning_rate&quot;\\n  input: &quot;train_step/gradients/conv_layer_0/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@conv_layer_0/conv_bias/conv_bias_0&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/GradientDescent/update_fc_layer_0/fc_kernel_0/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;fc_layer_0/fc_kernel_0&quot;\\n  input: &quot;train_step/GradientDescent/learning_rate&quot;\\n  input: &quot;train_step/gradients/AddN_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_0/fc_kernel_0&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/GradientDescent/update_fc_layer_0/fc_kernel/fc_bias_0/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;fc_layer_0/fc_kernel/fc_bias_0&quot;\\n  input: &quot;train_step/GradientDescent/learning_rate&quot;\\n  input: &quot;train_step/gradients/fc_layer_0/Add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_0/fc_kernel/fc_bias_0&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/GradientDescent/update_fc_layer_1/fc_kernel_1/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;fc_layer_1/fc_kernel_1&quot;\\n  input: &quot;train_step/GradientDescent/learning_rate&quot;\\n  input: &quot;train_step/gradients/AddN&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_1/fc_kernel_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/GradientDescent/update_fc_layer_1/fc_kernel/fc_bias_1/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;fc_layer_1/fc_kernel/fc_bias_1&quot;\\n  input: &quot;train_step/GradientDescent/learning_rate&quot;\\n  input: &quot;train_step/gradients/fc_layer_1/Add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_1/fc_kernel/fc_bias_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;train_step/GradientDescent&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^train_step/GradientDescent/update_conv_layer_0/conv_bias/conv_bias_0/ApplyGradientDescent&quot;\\n  input: &quot;^train_step/GradientDescent/update_conv_layer_0/conv_kernel_0/ApplyGradientDescent&quot;\\n  input: &quot;^train_step/GradientDescent/update_fc_layer_0/fc_kernel/fc_bias_0/ApplyGradientDescent&quot;\\n  input: &quot;^train_step/GradientDescent/update_fc_layer_0/fc_kernel_0/ApplyGradientDescent&quot;\\n  input: &quot;^train_step/GradientDescent/update_fc_layer_1/fc_kernel/fc_bias_1/ApplyGradientDescent&quot;\\n  input: &quot;^train_step/GradientDescent/update_fc_layer_1/fc_kernel_1/ApplyGradientDescent&quot;\\n}\\nnode {\\n  name: &quot;evaluate/ArgMax/dimension&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;evaluate/ArgMax&quot;\\n  op: &quot;ArgMax&quot;\\n  input: &quot;fc_layer_1/Add&quot;\\n  input: &quot;evaluate/ArgMax/dimension&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;output_type&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;evaluate/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;evaluate/ArgMax&quot;\\n  input: &quot;inputs/Placeholder_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;evaluate/error_num/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT64\\n        tensor_shape {\\n        }\\n        int64_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;evaluate/error_num/NotEqual&quot;\\n  op: &quot;NotEqual&quot;\\n  input: &quot;evaluate/sub&quot;\\n  input: &quot;evaluate/error_num/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;evaluate/error_num/ToInt64&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;evaluate/error_num/NotEqual&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n  attr {\\n    key: &quot;Truncate&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;evaluate/error_num/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;evaluate/error_num/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;evaluate/error_num/ToInt64&quot;\\n  input: &quot;evaluate/error_num/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;evaluate/LeNet_error_num/tags&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;evaluate/LeNet_error_num&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;evaluate/LeNet_error_num&quot;\\n  op: &quot;ScalarSummary&quot;\\n  input: &quot;evaluate/LeNet_error_num/tags&quot;\\n  input: &quot;evaluate/error_num/Sum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Merge/MergeSummary&quot;\\n  op: &quot;MergeSummary&quot;\\n  input: &quot;conv_layer_0/conv_layer/0/kernel&quot;\\n  input: &quot;conv_layer_0/conv_layer/0/bias&quot;\\n  input: &quot;fc_layer_0/fc_layer/0/kernel&quot;\\n  input: &quot;fc_layer_0/fc_layer/0/bias&quot;\\n  input: &quot;fc_layer_1/fc_layer/1/kernel&quot;\\n  input: &quot;fc_layer_1/fc_layer/1/bias&quot;\\n  input: &quot;loss/LeNet_loss&quot;\\n  input: &quot;evaluate/LeNet_error_num&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 8\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;model&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 6\\n          }\\n        }\\n        string_val: &quot;conv_layer_0/conv_bias/conv_bias_0&quot;\\n        string_val: &quot;conv_layer_0/conv_kernel_0&quot;\\n        string_val: &quot;fc_layer_0/fc_kernel/fc_bias_0&quot;\\n        string_val: &quot;fc_layer_0/fc_kernel_0&quot;\\n        string_val: &quot;fc_layer_1/fc_kernel/fc_bias_1&quot;\\n        string_val: &quot;fc_layer_1/fc_kernel_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 6\\n          }\\n        }\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2&quot;\\n  op: &quot;SaveV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/SaveV2/tensor_names&quot;\\n  input: &quot;save/SaveV2/shape_and_slices&quot;\\n  input: &quot;conv_layer_0/conv_bias/conv_bias_0&quot;\\n  input: &quot;conv_layer_0/conv_kernel_0&quot;\\n  input: &quot;fc_layer_0/fc_kernel/fc_bias_0&quot;\\n  input: &quot;fc_layer_0/fc_kernel_0&quot;\\n  input: &quot;fc_layer_1/fc_kernel/fc_bias_1&quot;\\n  input: &quot;fc_layer_1/fc_kernel_1&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;^save/SaveV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@save/Const&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 6\\n          }\\n        }\\n        string_val: &quot;conv_layer_0/conv_bias/conv_bias_0&quot;\\n        string_val: &quot;conv_layer_0/conv_kernel_0&quot;\\n        string_val: &quot;fc_layer_0/fc_kernel/fc_bias_0&quot;\\n        string_val: &quot;fc_layer_0/fc_kernel_0&quot;\\n        string_val: &quot;fc_layer_1/fc_kernel/fc_bias_1&quot;\\n        string_val: &quot;fc_layer_1/fc_kernel_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 6\\n          }\\n        }\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2/tensor_names&quot;\\n  input: &quot;save/RestoreV2/shape_and_slices&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;conv_layer_0/conv_bias/conv_bias_0&quot;\\n  input: &quot;save/RestoreV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@conv_layer_0/conv_bias/conv_bias_0&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_1&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;conv_layer_0/conv_kernel_0&quot;\\n  input: &quot;save/RestoreV2:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@conv_layer_0/conv_kernel_0&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_2&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;fc_layer_0/fc_kernel/fc_bias_0&quot;\\n  input: &quot;save/RestoreV2:2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_0/fc_kernel/fc_bias_0&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_3&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;fc_layer_0/fc_kernel_0&quot;\\n  input: &quot;save/RestoreV2:3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_0/fc_kernel_0&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_4&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;fc_layer_1/fc_kernel/fc_bias_1&quot;\\n  input: &quot;save/RestoreV2:4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_1/fc_kernel/fc_bias_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_5&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;fc_layer_1/fc_kernel_1&quot;\\n  input: &quot;save/RestoreV2:5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_1/fc_kernel_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/restore_all&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^save/Assign&quot;\\n  input: &quot;^save/Assign_1&quot;\\n  input: &quot;^save/Assign_2&quot;\\n  input: &quot;^save/Assign_3&quot;\\n  input: &quot;^save/Assign_4&quot;\\n  input: &quot;^save/Assign_5&quot;\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^conv_layer_0/conv_bias/conv_bias_0/Assign&quot;\\n  input: &quot;^conv_layer_0/conv_kernel_0/Assign&quot;\\n  input: &quot;^fc_layer_0/fc_kernel/fc_bias_0/Assign&quot;\\n  input: &quot;^fc_layer_0/fc_kernel_0/Assign&quot;\\n  input: &quot;^fc_layer_1/fc_kernel/fc_bias_1/Assign&quot;\\n  input: &quot;^fc_layer_1/fc_kernel_1/Assign&quot;\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.8894366973273261&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show the graph\n",
    "from ecbm4040.neuralnets.cnn_jupyter_tensorboard import show_graph \n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.import_meta_graph('model/lenet_1540801038.meta')\n",
    "    graph = tf.get_default_graph()\n",
    "    show_graph(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">__TODO:__</span> \n",
    "1. Complete the your own CNN in __ecbm4040/neuralnets/cnn.py__ with at least **65%** accuracy.\n",
    "2. Print out the training process and the best validation accuracy, save the `.meta` model in __model/__ folder.\n",
    "3. Attatch a screen shot of your tensorboard graph in the markdown cell below. Double click the cell and replace the example image with your own image. Here is a [Markdown Cheetsheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet#images) that may also help.\n",
    "\n",
    "__Hint__: \n",
    "1. You can copy and edit the code from `cnn_sample.py`\n",
    "2. The techniques in task-1 and task-2 will help. Check the corresponding functions in Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building my LeNet. Parameters: \n",
      "conv_featmap=[64, 32]\n",
      "fc_units=[84]\n",
      "conv_kernel_size=[3, 3]\n",
      "pooling_size=[2, 2]\n",
      "l2_norm=0.01\n",
      "seed=235\n",
      "learning_rate=0.001\n",
      "number of batches for training: 200\n",
      "epoch 1 \n",
      "Best validation accuracy! iteration:100 accuracy: 16.700000000000003%\n",
      "Best validation accuracy! iteration:200 accuracy: 26.5%\n",
      "epoch 2 \n",
      "Best validation accuracy! iteration:300 accuracy: 31.0%\n",
      "Best validation accuracy! iteration:400 accuracy: 34.099999999999994%\n",
      "epoch 3 \n",
      "Best validation accuracy! iteration:500 accuracy: 36.0%\n",
      "Best validation accuracy! iteration:600 accuracy: 37.8%\n",
      "epoch 4 \n",
      "Best validation accuracy! iteration:700 accuracy: 39.1%\n",
      "Best validation accuracy! iteration:800 accuracy: 40.0%\n",
      "epoch 5 \n",
      "Best validation accuracy! iteration:900 accuracy: 42.2%\n",
      "Best validation accuracy! iteration:1000 accuracy: 42.7%\n",
      "epoch 6 \n",
      "Best validation accuracy! iteration:1100 accuracy: 43.4%\n",
      "Best validation accuracy! iteration:1200 accuracy: 43.8%\n",
      "epoch 7 \n",
      "Best validation accuracy! iteration:1300 accuracy: 44.4%\n",
      "Best validation accuracy! iteration:1400 accuracy: 45.0%\n",
      "epoch 8 \n",
      "Best validation accuracy! iteration:1500 accuracy: 45.7%\n",
      "Best validation accuracy! iteration:1600 accuracy: 46.2%\n",
      "epoch 9 \n",
      "Best validation accuracy! iteration:1700 accuracy: 46.8%\n",
      "Best validation accuracy! iteration:1800 accuracy: 47.4%\n",
      "epoch 10 \n",
      "Best validation accuracy! iteration:1900 accuracy: 47.9%\n",
      "epoch 11 \n",
      "Best validation accuracy! iteration:2100 accuracy: 48.4%\n",
      "Best validation accuracy! iteration:2200 accuracy: 48.5%\n",
      "epoch 12 \n",
      "Best validation accuracy! iteration:2300 accuracy: 49.4%\n",
      "Best validation accuracy! iteration:2400 accuracy: 49.5%\n",
      "epoch 13 \n",
      "Best validation accuracy! iteration:2600 accuracy: 49.9%\n",
      "epoch 14 \n",
      "epoch 15 \n",
      "Best validation accuracy! iteration:2900 accuracy: 50.2%\n",
      "Best validation accuracy! iteration:3000 accuracy: 50.9%\n",
      "epoch 16 \n",
      "epoch 17 \n",
      "Best validation accuracy! iteration:3300 accuracy: 51.2%\n",
      "Best validation accuracy! iteration:3400 accuracy: 51.3%\n",
      "epoch 18 \n",
      "Best validation accuracy! iteration:3500 accuracy: 52.2%\n",
      "Best validation accuracy! iteration:3600 accuracy: 52.3%\n",
      "epoch 19 \n",
      "Best validation accuracy! iteration:3700 accuracy: 53.0%\n",
      "epoch 20 \n",
      "Best validation accuracy! iteration:3900 accuracy: 53.8%\n",
      "Traning ends. The best valid accuracy is 53.8. Model named lenet_1540865669.\n"
     ]
    }
   ],
   "source": [
    "from ecbm4040.neuralnets.cnn import my_training\n",
    "tf.reset_default_graph()\n",
    "# my_training(X_train, y_train, X_val, y_val, ...)\n",
    "\n",
    "my_training(X_train, y_train, X_val, y_val, \n",
    "        conv_featmap=[32, 32],\n",
    "        fc_units=[84],\n",
    "        conv_kernel_size=[3, 3],\n",
    "        pooling_size=[2, 2],\n",
    "        l2_norm=0.01,\n",
    "        seed=235,\n",
    "        learning_rate=1e-3,\n",
    "        epoch=20,\n",
    "        batch_size=245,\n",
    "        verbose=False,\n",
    "        pre_trained_model=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">__TODO:__</span>  replace the example image with your own tensorboard graph screenshot.\n",
    "![Tensorboard_2](./ecbm4040/notebook_images/task3_2_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the graph\n",
    "from ecbm4040.neuralnets.cnn_jupyter_tensorboard import show_graph \n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.import_meta_graph('model/[YOUR_MODEL_NAME].meta')\n",
    "    graph = tf.get_default_graph()\n",
    "    show_graph(graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
